# Rule: Guideline Text/Image ‚Üí FHIR JSON Bundle Transformation

## üéØ Purpose
This rule defines the complete workflow and prompt specification to convert **clinical guideline content** ‚Äî provided either as **diagram images** or **textual step-by-step descriptions** ‚Äî into validated **FHIR JSON Bundles**. It ensures consistent extraction, conversion, validation, integrity checking, and autofix processes so that the final output is a valid and self-contained Bundle (FHIR R4) ready for CDS implementation.

---

## üß† System Prompt (for the assistant/automation)

You are a **clinical guideline transformation expert** specialized in **FHIR/HL7, CDS, and guideline representation**. Your task is to transform a single clinical guideline ‚Äî provided either as an **image diagram** or a **structured text file describing the decision flow** ‚Äî into a validated FHIR JSON Bundle.

### Your responsibilities:
1. **Extract** structured content from the input (image or text): decision nodes, actions, diagnoses, data collection elements.
2. **Synthesize question structure** for decision/data-collection points: determine `type` (boolean|choice|string|integer|decimal|quantity|date|time|group|observation), infer answer options with stable `code`s, and normalize `stepId`/`linkId`.
3. **Derive explicit branching** by generating a machine-parseable `next` map for each step using the constrained grammar defined in this rule.
4. **Generate a structured Markdown file** following the Guideline Markdown Template.
5. **Produce a FHIR JSON Bundle** containing PlanDefinition, Library, ActivityDefinition, and Questionnaire.
6. **Run integrity verification** using `tools/integrity_check.py` and `tools/validate_bundle_integrity.py`.
7. **Ensure canonical integrity** ‚Äî all references resolve within the Bundle or are declared as external dependencies.
8. **Validate** the Bundle using the HL7 FHIR Validator until **0 validation errors** remain.

### Constraints
- Do **not** alter or invent clinical meaning.
- Use only standard code systems (ICD-10, LOINC, SNOMED). Missing codes ‚Üí mark TODO.
- Maintain machine-parseable Markdown with consistent naming conventions.

---

## üìÇ Directory and File Structure Convention

Each guideline must have its own subdirectory under `/guidelines/<base>/`.

For example, if the input file is:
```
fever-diagram.png
```
Then all generated artifacts must be stored in:
```
/guidelines/fever-diagram/
```

### Directory contents:
```
/guidelines/fever-diagram/
‚îú‚îÄ‚îÄ fever-diagram.md
‚îú‚îÄ‚îÄ fever-diagram.bundle.orig.json
‚îú‚îÄ‚îÄ fever-diagram.bundle.json
‚îú‚îÄ‚îÄ fever-diagram.integrity.report.txt
‚îú‚îÄ‚îÄ fever-diagram.bundle.report.txt
‚îú‚îÄ‚îÄ fever-diagram.bundle.autofix.log
‚îî‚îÄ‚îÄ fever-diagram.bundle.remediation.txt
```

Each run of the workflow should automatically create this subfolder if it does not exist.

---

## üìÑ Input Types and Expected Outputs

### Accepted Inputs
| Input Type | Description | Example |
|-------------|--------------|----------|
| `image` | Clinical guideline diagram (PNG, JPG, SVG) | `fever-diagram.png` |
| `text` | Structured or semi-structured text file describing decision steps, questions, and actions | `fever-guideline.txt` |

The automation must parse both forms equivalently: extract the logical decision flow, branching conditions, and resulting actions.

### Output Files per Input
| Output | Description |
|---------|-------------|
| `<base>.md` | Structured Markdown guideline |
| `<base>.bundle.json` | FHIR JSON Bundle (R4) |
| `<base>.integrity.report.txt` | Report generated by integrity validator |
| `<base>.bundle.report.txt` | HL7 Validator output |
| `<base>.bundle.autofix.log` | Autofix log (if applied) |
| `<base>.bundle.remediation.txt` | Manual fix report (if critical errors remain) |

---

## ü™∂ Guideline Markdown Template

### YAML Front-Matter
```yaml
id: fever-guideline
title: Evaluation of Fever
description: Diagnostic decision tree for fever causes.
version: 1.0.0
date: YYYY-MM-DD
authors:
  - name: <author>
fhirVersion: "4.0.1"
```

### Sections
- **Context / Scope**: textual background
- **Flow**: list of steps/questions and their logic
- **Actions**: list of resulting actions or recommendations
- **Notes / TODO**: pending code mappings, references

#### Example Flow
```markdown
1. stepId: recentTravel
   question: "Recent travel abroad?"
   type: boolean
   next:
     true: stepId=travelIncubation
     false: stepId=hospitalizationCheck

2. stepId: travelIncubation
   question: "Incubation period since return"
   type: choice
   answers:
     - code: lt21
       display: "< 21 days"
       next: action=propose-malaria
     - code: gt21
       display: "> 21 days"
       next: action=propose-tb
```

---

## üß© Step: Lightweight Markdown Integrity Check (using `tools/integrity_check.py`)

**Purpose:**  
Perform a quick integrity verification of the generated Markdown (`.md`) file before any conversion to JSON Bundle.
This ensures the Markdown contains valid front-matter, expected structure, and an identifiable source trace.

**Checks performed:**
- Parse simple YAML front-matter keys (`id`, `title`, `date`, `authors`, `fhirVersion`)
- Extract all `stepId` tokens within the Markdown Flow section
- Detect a ‚ÄúGenerated from ‚Ä¶‚Äù line (best-effort origin trace)
- If the front-matter includes `source-checksum: <sha256>`, compare SHA256 of the original image/text file against it

**Usage:**
```bash
python3 tools/integrity_check.py --md <guideline.md> \
  [--source <diagrams/foo.txt|diagrams/foo.png>] \
  [--report <out.txt>]
```

**Exit codes:**
| Code | Meaning |
|------|----------|
| 0 | All critical checks passed |
| 1 | Critical issues found (invalid or missing fields) |
| 2 | File missing or invalid usage |

**Typical pipeline usage:**
This check runs immediately after Markdown generation (Step 2 in the 5-step pipeline).  
If exit code ‚â† 0 ‚Üí stop and fix Markdown or source before proceeding to Bundle generation.

---

## üßÆ Step: Pre-Validation Integrity Check (using `tools/validate_bundle_integrity.py`)

**Purpose:**  
Verify the generated artifacts (Markdown and Bundle) are internally consistent and that the Bundle reflects the Markdown before any autofix or HL7 validation runs.

### Notes on the improved toolchain
- `tools/validate_bundle_integrity.py` now supports validating **Markdown (front-matter and extracted `stepId`s)**, **Bundle JSON**, and **cross-checks** between them.
- Use `tools/post_md_checks.py` as a small wrapper that converters can call immediately after producing the Markdown (and bundle if available). The wrapper writes `<base>.integrity.report.txt` next to the guideline files.

### Recommended Invocations

**When both Markdown and Bundle are available (recommended):**
```bash
python3 tools/validate_bundle_integrity.py --md <base>.md --bundle <base>.bundle.json --output <base>.integrity.report.txt
```

**Using the wrapper helper (recommended for converters):**
```bash
python3 tools/post_md_checks.py --md <base>.md --bundle <base>.bundle.json
```

**If only Markdown is available (no bundle yet):**
```bash
python3 tools/validate_bundle_integrity.py --md <base>.md --output <base>.integrity.report.txt
```

### Checks Performed
- Presence of required resources in the Bundle (PlanDefinition, Library, Questionnaire, ‚â•1 ActivityDefinition) when Bundle is provided
- YAML front-matter presence and required keys (`id`, `title`, `fhirVersion`)
- Extraction of `stepId`s from the Markdown Flow
- `linkId` ‚Üî `stepId` mapping (Questionnaire linkIds vs Markdown stepIds)
- Flow `next` grammar validity (allowed keys, presence/order of `else`) and resolution of all referenced `stepId`/`actionId` targets; units included for numeric thresholds when present in source text
- Canonical and reference consistency inside the Bundle
- ID and naming pattern conformity (e.g., `<id>-plan`, `<id>-bundle`)
- Library completeness (`type`, placeholder `content`)
- Orphan or unresolved references and unused resources

### Outcome Handling
- ‚úÖ **No critical errors**: proceed to autofix & HL7 Validator step
- ‚ö†Ô∏è **Warnings**: review report and decide if manual edits or autofix are needed
- ‚ùå **Critical errors**: stop and fix Markdown/Bundle; examine `<base>.integrity.report.txt`

### Report Output
- The tool writes a detailed report to `<base>.integrity.report.txt`
- Exits with code `0` (pass) or `1` (fail)

### Implementation Notes
- The Markdown parser extracts YAML front-matter and searches for `stepId` tokens in the Flow section.
- For robust YAML parsing, consider using `PyYAML` and enforcing strict schema.
- The cross-check lists any `stepId`s present in Markdown but missing from `Questionnaire.linkId`s (and vice versa) as warnings.

---

## üß© FHIR JSON Bundle Generation Rules

| Resource | Rules |
|-----------|-------|
| **Bundle** | `resourceType: "Bundle"`, `type: "collection"`, `id: <id>-bundle` |
| **PlanDefinition** | `id: <id>-plan`, references Library + ActivityDefinitions |
| **Library** | `id: <id>-library`, `type: logic-library`, `content` = placeholder base64 CQL |
| **Questionnaire** | `id: <id>-questionnaire`, `linkId` = `stepId` |
| **ActivityDefinition** | `id: <id>-activity-<actionId>`, kind = `ServiceRequest` or `Task` |

Use URN UUIDs for all internal canonical references: `urn:uuid:<uuid>`.

---

## ‚úÖ Integrity Checks (Markdown ‚Üí JSON Bundle)

Before validation, ensure:
- Bundle includes at least: PlanDefinition, Library, Questionnaire, ‚â•1 ActivityDefinition
- All resource IDs follow `<id>-<suffix>` pattern
- All canonical and definitionCanonical links resolve within the Bundle
- Every Bundle.entry has a valid `fullUrl`
- Library contains `type` and placeholder `content`
- Questionnaire items cover all `stepId`s from the Flow

Failures are classified as **auto-fixable** or **manual remediation**.

---

## üîß Autofix Rules

| Issue | Auto-Fix |
|--------|-----------|
| Missing `fullUrl` | Add `urn:uuid:<uuid>` |
| Example URLs | Replace `https://example.org/...` ‚Üí corresponding `urn:uuid` |
| Library missing `type` | Add `logic-library` CodeableConcept |
| Library missing `content` | Add base64 placeholder CQL |
| ID too long | Truncate using deterministic hash suffix |

Every modification must be logged to `<base>.bundle.autofix.log`.

---

## üß™ HL7 Validator Integration

### Run validator
```bash
java -jar tools/validator_cli.jar -version 4.0.1 \
  -output <base>.bundle.report.txt <base>.bundle.json
```

### Validation loop
1. Run validator ‚Üí parse report
2. If errors:
   - Apply autofix (if applicable)
   - Re-run validator (max 3 times)
3. If critical errors persist ‚Üí write remediation report and stop

Success condition: **0 validation errors** in the final Bundle.

---

## ‚öôÔ∏è Execution Workflow

### Mapped 5-step conversion process (strict alignment with requested workflow)

This section enforces the exact 5-step process: Markdown ‚Üí MD check ‚Üí MD‚ÜíBundle conversion ‚Üí MD‚ÜîBundle integrity checks ‚Üí final review.

**Step 1 ‚Äî Convert source (PNG | TXT) ‚Üí Markdown**

### üß¨ Diagnostic Guideline (TXT) Conversion Logic

**Purpose:**  
Handle conversion of *text-based diagnostic guidelines* (TXT) into structured Markdown and later into FHIR JSON Bundle ‚Äî aligned with HL7 examples for diagnostic pathways.

**Reference artifacts:**
- `PlanDefinition-activity-example-proposediagnosis-pd.ttl`
- `ActivityDefinition-activity-example-proposediagnosis-ad.ttl`
- `ActivityDefinition-cpg-proposediagnosistask-activitydefinition.ttl`
- `Library-proposediagnosis-library.ttl`
- `Questionnaire-activity-example-collectinformation-questionnaire.ttl`
- `PlanDefinition-chf-pathway.ttl`
- `PlanDefinition-cc-cpg-plan-ckd.ttl`
- `PlanDefinition-va-ckd-recommendations.ttl`

These resources illustrate how *diagnostic suggestion actions* and *information collection tasks* fit within HL7 CDS pathways.

---

#### Conversion heuristics for TXT guidelines

1. **Identify action verbs and triggers:**
   - ‚ÄúCheck‚Äù, ‚ÄúAssess‚Äù, ‚ÄúCollect‚Äù, ‚ÄúOrder‚Äù, ‚ÄúDiagnose‚Äù, ‚ÄúPropose‚Äù, ‚ÄúEvaluate‚Äù, ‚ÄúIf/Then‚Äù.
   - Map to FHIR resource roles:

     | Keyword | FHIR Resource | Example |
     |----------|----------------|----------|
     | *collect / assess* | `Questionnaire` / `ActivityDefinition` | Data collection step |
     | *propose diagnosis* | `ActivityDefinition` | Diagnostic suggestion |
     | *if/then condition* | `PlanDefinition.action.condition` | Conditional branching |
     | *order / test / measure* | `ServiceRequest` | Diagnostic test action |

2. **Extract diagnostic logic:**
   For each decision node in text, create a Markdown step block:
   ```markdown
   - stepId: checkFever
     question: "Does the patient have fever (>38¬∞C)?"
     type: boolean
     next:
       true: stepId=orderWBC
       false: stepId=checkOtherSymptoms
   ```

3. **Generate supporting resources:**
   - `PlanDefinition`: defines the overall diagnostic pathway and branching.
   - `ActivityDefinition`: one per diagnostic or collection action.
   - `Questionnaire`: defines all patient data questions inferred from the text.
   - `Library`: placeholder for logic (CQL expression), e.g., for threshold calculations.


4. **Generate example QuestionnaireResponses (optional but recommended):**
   - For each generated `Questionnaire`, create one or more `QuestionnaireResponse` examples to demonstrate expected data capture.
   - Each `QuestionnaireResponse` should:
     - Reference the corresponding `Questionnaire` via `QuestionnaireResponse.questionnaire = "urn:uuid:<questionnaire-id>"`.
     - Include sample `item.answer` values aligned with expected types (boolean, choice, string, quantity‚Ä¶).
     - Reflect realistic clinical scenarios when available (e.g., ‚ÄúYes‚Äù for fever, ‚ÄúPositive‚Äù for sputum test).
   - Example:
     ```json
     {
       "resourceType": "QuestionnaireResponse",
       "id": "qr-example-sputum",
       "status": "completed",
       "questionnaire": "urn:uuid:questionnaire-sputum",
       "item": [
         {
           "linkId": "sputum-result",
           "text": "Sputum test result",
           "answer": [{ "valueString": "Positive" }]
         }
       ]
     }
     ```
   - These resources are valuable for downstream validation and example testing.
   - When included, link them in `Bundle.entry` and ensure `PlanDefinition.action.relatedArtifact` references at least one example QuestionnaireResponse.


5. **Maintain traceability:**
   Include in Markdown YAML:
   ```yaml
   source-type: text
   source-file: diagnostic-guideline.txt
   source-checksum: <sha256>
   ```
   And at the end of the file:
   ```
   Generated from diagnostic-guideline.txt
   ```

6. **Mapping considerations (HL7 alignment):**
   - `PlanDefinition.action.code` ‚Üí use `http://hl7.org/fhir/CodeSystem/action-type` or `http://hl7.org/fhir/uv/cpg/CodeSystem/cpg-action-type`.
   - `ActivityDefinition.kind` ‚Üí `ServiceRequest`, `Task`, or `Observation`.
   - `Questionnaire.item.linkId` = `stepId`.
   - Use `Library` for logical rules or scoring (e.g., CURB-65, SOFA).

7. **Validation expectations:**
   - Ensure `PlanDefinition` includes both *collect-information* and *propose-diagnosis* actions.
   - Ensure all referenced `ActivityDefinition` instances exist in the Bundle.
   - Ensure each Questionnaire covers all collected inputs.

---

#### Example (excerpt)
```
If patient has persistent cough ‚Üí collect sputum test
If sputum positive ‚Üí propose diagnosis: Tuberculosis
Else ‚Üí consider viral pneumonia
```

‚Üí Transforms into Markdown:

```markdown
1. stepId: coughCheck
   question: "Does the patient have persistent cough?"
   type: boolean
   next:
     true: stepId=sputumTest
     false: stepId=end

2. stepId: sputumTest
   action: collect-information
   question: "Collect sputum test result"
   type: observation
   next:
     positive: action=propose-tuberculosis
     negative: action=propose-viralpneumonia
```

## üß± Question and decision structure specification (AI authoring rules)

This section defines the exact authoring contract the AI must follow when creating question blocks and decision branches from text or diagram sources. The goal is a deterministic, machine-parseable Flow that maps 1:1 to Questionnaire items and PlanDefinition actions.

### A. Canonical question block schema

- Required keys per block:
  - `stepId` (kebab-case, unique; chars: a‚Äìz, 0‚Äì9, '-')
  - one of: `question` (display text) OR `action` (when it is an action-only node)
  - `type` for question nodes: `boolean|choice|string|integer|decimal|quantity|date|time|group|observation`
  - Optional: `required` (true|false), `unit` (for numeric/quantity), `answers` (for choice), `notes`, `variables` (list of snake_case names)
  - `next`: branching map (see section B)

- Type-specific guidance:
  - `boolean`: implicit answers `true|false`. Only add custom labels if clinically needed; identifiers remain `true|false`.
  - `choice`: provide `answers` as objects `{ code, display }`. Codes are lowercase kebab-case; do not use standard code systems unless explicitly provided in the source.
  - `integer|decimal|quantity`: use numeric thresholds; include `unit` when present in text (¬∞C, mmHg, mg/dL, %, /uL...).
  - `observation`: for specific test/result capture; typically paired with an `ActivityDefinition` and/or `ServiceRequest`.
  - `group`: to cluster related items; may still have `next` if completion triggers a branch.

- Normalization rules:
  - `stepId` = short English slug from the question/action; no spaces/diacritics.
  - `answers[].code` = normalized slug of the option; preserve meaning; if ambiguous, add `notes: "[REVIEW_REQUIRED]: ambiguous option"`.
  - Never translate identifiers (`stepId`, `answers[].code`, canonical URNs).

### B. Branching grammar for `next`

Use a constrained grammar so validators can statically analyze branches.

- Boolean questions:
  - `next:` with keys `true` and/or `false` ‚Üí `stepId=<id>` or `action=<action-id>`

- Choice questions:
  - `next:` with keys equal to `answers[].code` and optional `else` fallback

- Numeric/quantity thresholds (`integer|decimal|quantity`):
  - Allowed keys: `lt`, `le`, `eq`, `ge`, `gt`, `between`
  - Forms:
    - `lt:<value>[ <unit>]` ‚Üí `stepId|action`
    - `between:<low>-<high>[ <unit>]` ‚Üí `stepId|action`
    - `ge:<value>[ <unit>]` ‚Üí `stepId|action`
  - Example:
    - `next:`
      `  ge:38 ¬∞C: stepId=order-wbc`
      `  lt:38 ¬∞C: stepId=check-other-symptoms`

- Compound conditions:
  - Use `all:` (AND) or `any:` (OR) arrays of predicates; predicates reference prior `stepId`s with operators `=, !=, <, <=, >, >=, in, contains`.
  - Example:
    - `next:`
      `  all:`
      `    - fever-present=true`
      `    - wbc-count ge 12000 /uL`
      `  then: action=order-chest-xray`
      `  else: stepId=viral-panel`

- Terminal:
  - `next: end`

- Target kinds:
  - `stepId=<id>` to continue flow
  - `action=<action-id>` to trigger an action node (ActivityDefinition)

Validation constraints:
  - All referenced ids must exist as `stepId` or declared `actionId`
  - If a unit is present in source text, include it in numeric keys; otherwise omit
  - `else` (if present) must be the last fallback

### C. Mapping to FHIR artifacts

- Questionnaire
  - `item.linkId` = `stepId`; `item.type` from `type`
  - Choice options ‚Üí `answerOption.valueCoding` with local codes unless a standard is explicitly given
  - Ensure all `stepId`s appear as `linkId`s; enableWhen may be derived but PlanDefinition conditions are authoritative

- PlanDefinition
  - Create one `action` per question and per action node; deterministic ids `<id>-action-<stepId>`
  - Encode branching via `action.condition` and `relatedAction`
  - `action=<action-id>` generates an `ActivityDefinition` (`kind: ServiceRequest|Task|Observation`) referenced via `definitionCanonical`

- Library
  - Provide placeholder CQL for compound/threshold logic; ensure `type: logic-library` and `content` placeholder

### D. Text ‚Üí structure cues

- Yes/No cues ‚Üí `boolean` (e.g., "has/with/without", "present/absent")
- Enumerations ‚Üí `choice` (e.g., lists, categories, stages)
- Thresholds ‚Üí numeric with operators (`>`, `>=`, `<`, `<=`, "between") and units
- Tests/orders/results ‚Üí `observation` with paired action

Ambiguity:
- Prefer least assumptive typing; add `notes: "[REVIEW_REQUIRED]: <reason>"` when uncertain
- Never fabricate standard codes; use `codes: TODO` placeholders when needed

### E. Mini examples

1) Boolean

```
- stepId: fever-present
  question: "Fever ‚â• 38¬∞C?"
  type: boolean
  next:
    true: stepId=order-wbc
    false: stepId=check-other-symptoms
```

2) Choice with else

```
- stepId: cough-duration
  question: "Cough duration"
  type: choice
  answers:
    - code: lt3w
      display: "< 3 weeks"
    - code: ge3w
      display: "‚â• 3 weeks"
  next:
    ge3w: action=propose-tuberculosis
    else: stepId=viral-workup
```

3) Numeric with unit thresholds

```
- stepId: oxygen-saturation
  question: "SpO2 (%)"
  type: integer
  next:
    lt:90 %: action=admit-oxygen
    ge:90 %: stepId=consider-outpatient
```

4) Compound (all)

```
- stepId: consolidation-decide
  question: "Consolidation suspected?"
  type: boolean
  next:
    all:
      - fever-present=true
      - wbc-count ge 12000 /uL
    then: action=order-chest-xray
    else: stepId=viral-panel
```

Ghi ch√∫ (ti·∫øng Vi·ªát): T·∫°o block c√¢u h·ªèi theo schema tr√™n, d√πng `next` v·ªõi c√∫ ph√°p chu·∫©n (boolean, choice, ng∆∞·ª°ng s·ªë, all/any). `stepId`/`linkId` ph·∫£i ƒë·ªìng nh·∫•t v√† kh√¥ng d·ªãch. N·∫øu m∆° h·ªì, th√™m `[REVIEW_REQUIRED]` trong `notes`.

---

### üß† Implementation guidance for AI

- Use rule-based parsing for `if`, `then`, `else`, `and`, `or` tokens to derive conditional tree.
- Group diagnostic propositions under `ActivityDefinition` resources with `kind: ServiceRequest`.
- Link to `Library` logic for derived expressions or scoring systems.
- Always output Markdown following the **same schema** as diagram-sourced guidelines to ensure downstream tools (integrity check, validator) work uniformly.

- Input: `/inputs/<file>` (image or text)
- Convert into `/guidelines/<base>/<base>.md` using the converter (OCR + parser for images, direct parse for text).
- Save intermediate artifacts in the guideline folder.

**Step 2 ‚Äî Check & finalize Markdown**
- Immediately run the lightweight Markdown integrity check:
```bash
python3 tools/integrity_check.py --md /guidelines/<base>/<base>.md --report /guidelines/<base>/<base>.integrity.report.txt
```
- If the integrity tool reports **critical errors**, **stop** and return to Step 1 to fix the source/Markdown. Do not proceed to Step 3 until the Markdown passes.
- If only **warnings**, document them in the integrity report and decide: either fix now (preferred) or proceed with explicit acceptance.

**Exit condition for Step 2:** `<base>.integrity.report.txt` exists and shows no critical errors (exit code 0).

**Step 3 ‚Äî Convert Markdown ‚Üí Bundle JSON**
- Only run after Step 2 passes.
- Run the Markdown-to-Bundle generator to create `/guidelines/<base>/<base>.bundle.json` and save the original as `.bundle.orig.json`.
- Ensure the generator follows the Bundle generation rules (resource ids, fullUrl URNs, Library content placeholders, Questionnaire linkIds mapping to stepIds).

**Step 4 ‚Äî Integrity check: Markdown ‚Üî Bundle**
- Run full integrity cross-check using both inputs:
```bash
python3 tools/validate_bundle_integrity.py --md /guidelines/<base>/<base>.md \
  --bundle /guidelines/<base>/<base>.bundle.json \
  --output /guidelines/<base>/<base>.integrity.report.txt
```
- The tool classifies issues into **critical**, **warnings**, and **info**.
  - **Critical**: missing PlanDefinition/Library/Questionnaire, broken canonicals, missing linkId mappings. If critical ‚Üí revert to Step 3 and fix conversion logic or Markdown content. Repeat Step 3 and Step 4 until no critical errors remain.
  - **Warnings**: missing codes, minor naming deviations, unused resources ‚Äî address as needed.

**Step 5 ‚Äî Final review & HL7 validation**
- After Step 4 passes (no critical errors), run autofix (deterministic fixes) then HL7 Validator:
```bash
# optional autofix stage (applies deterministic safe fixes)
python3 tools/autofix_bundle.py --bundle /guidelines/<base>/<base>.bundle.json --log /guidelines/<base>/<base>.bundle.autofix.log

# run HL7 validator
java -jar tools/validator_cli.jar -version 4.0.1 \
  -output /guidelines/<base>/<base>.bundle.report.txt /guidelines/<base>/<base>.bundle.json
```
- If HL7 validator returns **0 errors** ‚Üí accept and mark the bundle as final.
- If HL7 validator returns errors: classify them. If auto-fixable, apply deterministic fixes and re-run (up to N=3). If critical, create `/guidelines/<base>/<base>.bundle.remediation.txt` with manual remediation instructions and stop.

### Loop and governance rules
- **Do not** proceed to the next step while the current step has unresolved critical errors.
- When an error requires returning to a prior step, return **only to the immediately previous** step (i.e., on MD critical errors return to Step 1; on Bundle conversion errors return to Step 3). Avoid skipping steps to reduce churn.
- Keep all reports (`.integrity.report.txt`, `.bundle.report.txt`, `.bundle.autofix.log`) in the same guideline folder for auditability.

### Checklist automation hooks
- The pipeline should implement a simple state machine that tracks step status: `MD_CREATED`, `MD_VALIDATED`, `BUNDLE_CREATED`, `BUNDLE_INTEGRITY_PASSED`, `HL7_VALIDATED`.
- Each step writes a small status file `/guidelines/<base>/.state` and timestamp to aid automation restart and audit.

---

## üß∞ Implementation Guidelines
- **Languages:** Python or Node.js
- **Recommended modules:** `md_parser`, `bundle_builder`, `integrity_checker`, `autofix`, `validator_runner`, `reporter`
- **UUID Strategy:** Deterministic UUIDv5 using namespace `uuid.NAMESPACE_URL` and name `<bundle-id>|<resourceType>|<resource-id>`
- **Test cases:**
  - ‚úÖ Happy path ‚Äî valid Markdown ‚Üí passes first validation
  - ‚ö†Ô∏è Missing fullUrl ‚Äî fixed automatically
  - ‚ö†Ô∏è Missing Library.type/content ‚Äî fixed automatically
  - ‚öôÔ∏è Integrity check ‚Äî detects missing references or IDs before validation

---

## üì¶ Deliverables Checklist
- [ ] `/guidelines/<base>/<base>.md`
- [ ] `/guidelines/<base>/<base>.bundle.orig.json`
- [ ] `/guidelines/<base>/<base>.bundle.json`
- [ ] `/guidelines/<base>/<base>.integrity.report.txt`
- [ ] `/guidelines/<base>/<base>.bundle.report.txt`
- [ ] `/guidelines/<base>/<base>.bundle.autofix.log`
- [ ] `/guidelines/<base>/<base>.bundle.remediation.txt` (if needed)

---

## Ng√¥n ng·ªØ & D·ªãch thu·∫≠t (Language & Translation) ‚Äî B·ªï sung cho phi√™n b·∫£n v2.6.1

### M·ª•c ti√™u
Khi ngu·ªìn (·∫£nh ho·∫∑c t·ªáp vƒÉn b·∫£n) **kh√¥ng ph·∫£i ti·∫øng Vi·ªát**, pipeline s·∫Ω:
- Ph√°t hi·ªán ng√¥n ng·ªØ ngu·ªìn.
- D·ªãch ph·∫ßn n·ªôi dung hi·ªÉn th·ªã (question, display, notes, question text, item.display, step text, description, v.v.) sang **Ti·∫øng Vi·ªát** v√† t·∫°o th√™m m·ªôt phi√™n b·∫£n Markdown c√≥ h·∫≠u t·ªë `.vi.md` (v√≠ d·ª• `fever-diagram.vi.md`).
- **KH√îNG** thay ƒë·ªïi c√°c m√£ chu·∫©n (ICD-10, LOINC, SNOMED, codeableConcept codes), `stepId`, `linkId`, canonical URNs, bi·ªÉu th·ª©c CQL; gi·ªØ nguy√™n logic/ƒëi·ªÅu ki·ªán.
- L∆∞u gi·ªØ file g·ªëc v√† metadata ƒë·ªÉ ph·ª•c v·ª• truy v·∫øt (traceability) v√† audit.

### Nguy√™n t·∫Øc ch√≠nh (kh√¥ng th∆∞∆°ng l∆∞·ª£ng)
1. **Ch·ªâ d·ªãch ph·∫ßn hi·ªÉn th·ªã**: m·ªçi `id`, `code`, `stepId`, `linkId`, canonical URL, v√† code block (v√≠ d·ª• CQL, JSON Logic) ph·∫£i ƒë∆∞·ª£c gi·ªØ nguy√™n ‚Äî kh√¥ng d·ªãch, kh√¥ng ƒë·ªïi.
2. **B·∫£o to√†n t√≠nh ch√≠nh x√°c l√¢m s√†ng**: kh√¥ng suy di·ªÖn, kh√¥ng th√™m ho·∫∑c b·ªõt th√¥ng tin l√¢m s√†ng. N·∫øu thu·∫≠t ng·ªØ m∆° h·ªì, ƒë√°nh d·∫•u `[REVIEW_REQUIRED]`.
3. **Traceability & Metadata**: m·ªói file `.vi.md` ph·∫£i c√≥ YAML front-matter m·ªü r·ªông ghi r√µ ngu·ªìn, c√¥ng c·ª• d·ªãch, confidence, checksum, v√† danh s√°ch ƒëo·∫°n vƒÉn b·ªã flag.
4. **Human-in-the-loop**: t·ª± ƒë·ªông d·ªãch nh∆∞ng b·∫Øt bu·ªôc review n·∫øu:
   - `detection_confidence < 0.95`, ho·∫∑c
   - c√≥ b·∫•t k·ª≥ `[REVIEW_REQUIRED]` flag n√†o, ho·∫∑c
   - guideline c√≥ r·ªßi ro l√¢m s√†ng cao (ƒë∆∞·ª£c x√°c ƒë·ªãnh b·ªüi tag `clinical-risk: high` ho·∫∑c API).

### B∆∞·ªõc b·ªï sung trong pipeline (Step 1.5 ‚Äî Language Detection & Translation)
- **Step 1.1** ‚Äî (hi·ªán c√≥): Convert source ‚Üí Markdown (gi·ªØ nguy√™n ng√¥n ng·ªØ ngu·ªìn).
- **Step 1.5** ‚Äî *M·ªöI*: Ph√°t hi·ªán ng√¥n ng·ªØ v√†, n·∫øu c·∫ßn, t·∫°o `.vi.md`.
  1. Detect language (g·ªçi model/langdetect), tr·∫£ v·ªÅ `language` v√† `detection_confidence`.
  2. N·∫øu `language != 'vi'` v√† `detection_confidence >= 0.7`:
     - D·ªãch c√°c tr∆∞·ªùng hi·ªÉn th·ªã sang ti·∫øng Vi·ªát.
     - Gi·ªØ nguy√™n t·∫•t c·∫£ identifiers v√† m√£.
     - Th√™m d·∫•u `<!-- TRANSLATION: auto -->` ·ªü ƒë·∫ßu file `.vi.md`.
     - Th√™m YAML front-matter nh∆∞ m·∫´u b√™n d∆∞·ªõi.
     - Ghi file log `/guidelines/<base>/<base>.translation.log`.
  3. N·∫øu `detection_confidence < 0.7`, v·∫´n t·∫°o `.vi.md` nh∆∞ng ƒë√°nh d·∫•u `translation_notes: low_confidence` v√† b·∫Øt bu·ªôc `human_review_required: true`.

### M·∫´u YAML front-matter cho `<base>.vi.md`
```yaml
id: <base-id>
title: <title in Vietnamese or translated>
description: <short description in Vietnamese>
version: <version>
date: YYYY-MM-DD
authors:
  - name: <author>
fhirVersion: "4.0.1"

# Language / translation metadata
language: vi
translated_from:
  file: <original-file>            # e.g. fever-diagram.png or fever-diagram.md
  language: <detected-language>    # e.g. en
  detection_confidence: 0.98
translation_tool:
  name: "<translator-name>"        # e.g. "translate-service-name-or-model"
  version: "vX.Y"
translation_date: YYYY-MM-DDTHH:MM:SSZ
translation_checksum: "<sha256-of-translated-md>"
translation_notes: |
  - preserve_codes: true
  - human_review_required: false
  - flagged_items: 0
```

### ƒê·ªãnh d·∫°ng translation.log (v√≠ d·ª•)
```
2025-10-16T08:00:00Z - SOURCE: fever-diagram.png (en, conf=0.99)
2025-10-16T08:00:05Z - TRANSLATION_TOOL: translate-service v2.1
2025-10-16T08:00:10Z - GENERATED: fever-diagram.vi.md (sha256: ...)
2025-10-16T08:00:10Z - FLAGGED: 2 items -> review_required
2025-10-16T08:00:12Z - NEXT: created review task #TR-1234
```

### Ki·ªÉm tra t√≠nh to√†n v·∫πn (Integrity) gi·ªØa b·∫£n g·ªëc v√† b·∫£n d·ªãch
- `tools/validate_bundle_integrity.py` v√† `tools/integrity_check.py` ph·∫£i:
  - So s√°nh `stepId`/`linkId` gi·ªØa `<base>.md` v√† `<base>.vi.md`; m·ªçi mismatch ph·∫£i b√°o l·ªói.
  - Ch·ª©ng th·ª±c r·∫±ng m·ªçi m√£ chu·∫©n v·∫´n t·ªìn t·∫°i v√† kh√¥ng b·ªã d·ªãch.
  - T·∫°o report `fever-diagram.integrity.report.txt` li·ªát k√™:
    - unchanged identifiers
    - translated display texts
    - flagged items

### Quy t·∫Øc ƒë·ªÉ bundle generation
- M·∫∑c ƒë·ªãnh: **bundle ƒë∆∞·ª£c t·∫°o t·ª´ file g·ªëc** (`<base>.md`) ƒë·ªÉ b·∫£o to√†n m√£/code.
- N·∫øu ng∆∞·ªùi v·∫≠n h√†nh ch·ªçn `--use-translated-md`:
  - Y√™u c·∫ßu flag `translation_verified: true` trong YAML front-matter.
  - N·∫øu kh√¥ng c√≥ flag n√†y, pipeline ph·∫£i fail v√† kh√¥ng t·∫°o bundle.
- Khi bundle ƒë∆∞·ª£c t·∫°o t·ª´ `.vi.md` ph·∫£i ghi r√µ trong bundle metadata:
  - `generated_from: <base>.vi.md`
  - `translation_verified: true`
  - `translation_tool` v√† `translation_date`

### Ghi ch√∫ v·ªÅ thu·∫≠t ng·ªØ y t·∫ø
- N·∫øu c√≥ m√£ chu·∫©n (ICD/LOINC/SNOMED) k√®m theo thu·∫≠t ng·ªØ ‚Äî d·ªãch thu·∫≠t ph·∫£i hi·ªÉn th·ªã c·∫£ nh√£n ti·∫øng Vi·ªát v√† gi·ªØ m√£ chu·∫©n, v√≠ d·ª•:
  - `- label: "Sepsis (Nhi·ªÖm tr√πng huy·∫øt)"`
  - N·∫øu kh√¥ng c√≥ m√£ chu·∫©n, th√™m `possible_translations` v√† tag `[REVIEW_REQUIRED]`.

### Human Review Workflow (t√≠ch h·ª£p)
- T·ª± ƒë·ªông t·∫°o task review khi:
  - `flagged_items > 0` OR `detection_confidence < 0.95` OR guideline tag `clinical-risk: high`.
- Task review ph·∫£i cho ph√©p reviewer:
  - So s√°nh side-by-side b·∫£n g·ªëc v√† b·∫£n d·ªãch.
  - Ch·ªânh s·ª≠a tr·ª±c ti·∫øp file `.vi.md`.
  - X√°c nh·∫≠n `translation_verified: true` v√† c·∫≠p nh·∫≠t front-matter.

### T√™n file & pattern
- Phi√™n b·∫£n ti·∫øng Vi·ªát: `<base>.vi.md` (v√≠ d·ª• `fever-diagram.vi.md`).
- Phi√™n b·∫£n g·ªëc gi·ªØ nguy√™n: `<base>.md`.
- Bundle file names gi·ªØ d·∫°ng: `<base>.bundle.json`. N·∫øu bundle d·ª±a tr√™n `.vi.md`, th√™m tr∆∞·ªùng `generated_from` trong metadata.

### Tests & CI (khuy·∫øn ngh·ªã)
- Th√™m test unit/integration:
  - `test_translation_preserves_identifiers()` ‚Äî ki·ªÉm tra m·ªçi `id`/`code` kh√¥ng ƒë·ªïi.
  - `test_translation_front_matter()` ‚Äî ki·ªÉm tra front-matter c√≥ ƒë·ªß tr∆∞·ªùng metadata.
  - `test_translation_integrity_report()` ‚Äî ch·∫°y `integrity_check` v√† ƒë·∫£m b·∫£o kh√¥ng c√≥ mismatch.
- Trong CI pipeline:
  - Ch·∫°y detection -> translation b∆∞·ªõc t·∫Øt (dry-run) ƒë·ªÉ ph√°t hi·ªán l·ªói tr∆∞·ªõc khi merge.
  - N·∫øu m·ªôt PR th√™m `.vi.md` m√† kh√¥ng c√≥ `translation_notes` ho·∫∑c `translation_checksum`, CI ph·∫£i fail.

### V√≠ d·ª• c·∫•u tr√∫c th∆∞ m·ª•c sau khi th√™m t√≠nh nƒÉng
```
/guidelines/fever-diagram/
‚îú‚îÄ‚îÄ fever-diagram.png
‚îú‚îÄ‚îÄ fever-diagram.md                # original (English)
‚îú‚îÄ‚îÄ fever-diagram.vi.md             # Vietnamese translation (auto)
‚îú‚îÄ‚îÄ fever-diagram.bundle.orig.json
‚îú‚îÄ‚îÄ fever-diagram.bundle.json
‚îú‚îÄ‚îÄ fever-diagram.integrity.report.txt
‚îú‚îÄ‚îÄ fever-diagram.translation.log
‚îî‚îÄ‚îÄ review/
    ‚îî‚îÄ‚îÄ TR-1234/
        ‚îú‚îÄ‚îÄ diff.html
        ‚îú‚îÄ‚îÄ reviewer_notes.md
        ‚îî‚îÄ‚îÄ reviewer: Dr. Nguy·ªÖn VƒÉn A
```

### T√≥m t·∫Øt ng·∫Øn g·ªçn c√°c thay ƒë·ªïi c·∫ßn implement
1. Th√™m Step 1.5 (Language detection + auto-translation).
2. B·ªï sung YAML front-matter cho m·ªçi `.vi.md`.
3. Ghi log translation v√† t·∫°o review tasks cho c√°c tr∆∞·ªùng h·ª£p c·∫ßn ng∆∞·ªùi review.
4. C·∫≠p nh·∫≠t tools validate/integrity ƒë·ªÉ ki·ªÉm tra t∆∞∆°ng th√≠ch gi·ªØa b·∫£n g·ªëc v√† b·∫£n d·ªãch.
5. CI tests b·∫Øt bu·ªôc ki·ªÉm tra preserve identifiers & metadata.

---

END OF TRANSLATION SUPPLEMENT
